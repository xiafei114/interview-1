1. Kafka为什么要使用分区的概念而不是直接使用主题

   提高并发能力, 同一个消费组下的消费者读取不同分区下的数据并发消费。不同的分区分布在不同的broker上, 每一台机器都可以独立的进行读写, 增强集群的高可用

2. 分区策略
   	- 轮训分区
   	- 随机分区
   	- Key-Order分区(自定义分区): 按照业务属性进行进去, 当业务需要保证一定的顺序处理时, 同一个业务属性下的数据进入到同一个分区 
   	- 自定义分区

3. 数据压缩

   producer 压缩, broker 保持, comsumer 消费

   	- 当producer和broker设置的压缩算法不一致时, broker会对数据进行重新压缩
   	- 当同一个kafka使用了不同版本的消息时, 为了兼容老版本, broker会将数据从新版本转化成老版本
   	- broker解压缩会进行数据的校验

![img](https://static001.geekbang.org/resource/image/cf/68/cfe20a2cdcb1ae3b304777f7be928068.png)



**数据压缩的最佳实践**

- 数据压缩非常吃CPU资源, 当CPU资源紧缺时，尽量少开启压缩
- CPU充足时, 考虑打开压缩, 减少带宽的损耗
- 尽量避免kafka消息协议的版本不一致, 减少broker端对数据的解压缩以及协议的转化



